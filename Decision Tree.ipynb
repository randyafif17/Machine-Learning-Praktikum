{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4a2d26e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (2391598445.py, line 125)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[7], line 125\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(splits) weight_ig)\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('Preprocessing/BMIdata.csv')\n",
    "\n",
    "data['obese'] = (data.Index >= 4).astype('int')\n",
    "data.drop('Index', axis = 1, inplace = True)\n",
    "\n",
    "print(\"Misclassified when cutting at 100kg:\", data.loc[(data['Weight']>=100) & (data['obese']==0),:].shape[0], \"\\n\", \"Misclassified when cutting at 80kg:\", data.loc[(data['Weight']>=80) & (data['obese']==0),:].shape[0])\n",
    "\n",
    "# Entropy\n",
    "def entropy(y):\n",
    "# Given a Pandas Series, it calculates the entropy.\n",
    "# y: variable with which calculate entropy.\n",
    "\n",
    "    if isinstance(y, pd.Series):\n",
    "        a = y.value_counts()/y.shape[0]\n",
    "        entropy = np.sum(-a*np.log2(a+1e-9))\n",
    "        return(entropy)    \n",
    "    else:\n",
    "        raise('Object must be a Pandas Series.')\n",
    "    \n",
    "entropy(data.Gender)\n",
    "\n",
    "# Gini\n",
    "def gini_impurity(y):\n",
    "    if isinstance(y, pd.Series):\n",
    "        p = y.value_counts()/y.shape[0]\n",
    "        gini = 1-np.sum(p**2)\n",
    "        return(gini)\n",
    "    \n",
    "    else:\n",
    "        raise('Object must be a Pandas Series.')\n",
    "gini_impurity(data.Gender)\n",
    "\n",
    "# Information Gain (IG)\n",
    "def variance(y):\n",
    "    if(len(y) == 1):\n",
    "        return 0\n",
    "    else:\n",
    "        return y.var()\n",
    "    \n",
    "def information_gain(y, mask, func=entropy):\n",
    "    a = sum(mask)\n",
    "    b = mask.shape[0] - a\n",
    "\n",
    "    if(a == 0 or b ==0):\n",
    "        ig = 0\n",
    "        \n",
    "    else:\n",
    "        if y.dtypes != 'O':\n",
    "            ig = variance(y) - (a/(a+b)* variance(y[mask])) - (b/(a+b)*variance(y[-mask]))\n",
    "            \n",
    "        else:\n",
    "            ig = func(y)-a/(a+b)*func(y[mask])-b/(a+b)*func(y[-mask])\n",
    "        \n",
    "    return ig\n",
    "\n",
    "import itertools\n",
    "\n",
    "def categorical_options(a):\n",
    "    a = a.unique()\n",
    "    \n",
    "    opt = []\n",
    "    for L in range(0, len(a)+1):\n",
    "        for subset in itertools.combinations(a, L):\n",
    "            subset = list(subset)\n",
    "            opt.append(subset)\n",
    "\n",
    "    return opt[1:-1]\n",
    "\n",
    "def max_information_gain_split(x, y, func=entropy):\n",
    "    \n",
    "    split_value = []\n",
    "    ig = []\n",
    "    \n",
    "    numeric_variable = True if x.dtypes != 'O' else False\n",
    "\n",
    "    # Create options according to variable type\n",
    "    if numeric_variable:\n",
    "        options = x.sort_values().unique()[1:]\n",
    "    else:\n",
    "        options = categorical_options(x)\n",
    "    \n",
    "    # Calculate ig for all values\n",
    "    for val in options:\n",
    "        mask = x < val if numeric_variable else x.isin(val)\n",
    "        val_ig = information_gain(y, mask, func)\n",
    "        # Append results\n",
    "        ig.append(val_ig)\n",
    "        split_value.append(val)\n",
    "    \n",
    "    # Check if there are more than 1 results if not, return False\n",
    "    if len(ig) == 0:\n",
    "        return(None,None,None, False)\n",
    "    \n",
    "    else:\n",
    "    # Get results with highest IG\n",
    "        best_ig = max(ig)\n",
    "        best_ig_index = ig.index(best_ig)\n",
    "        best_split = split_value[best_ig_index]\n",
    "        return(best_ig,best_split,numeric_variable, True)\n",
    "\n",
    "weight_ig, weight_split, _, _ = max_information_gain_split(data['Weight'], data['obese'],)\n",
    "print(\"The best split for Weight is when the variable is less than \", weight_split,\"\\nInformation Gain for that split is:\", weight_ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82171b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000281</td>\n",
       "      <td>0.019684</td>\n",
       "      <td>0.106252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Male]</td>\n",
       "      <td>174</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender    Height    Weight\n",
       "0 -0.000281  0.019684  0.106252\n",
       "1    [Male]       174       103\n",
       "2     False      True      True\n",
       "3      True      True      True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop('obese', axis= 1).apply(max_information_gain_split, y = data['obese'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7ea8dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1] \n",
      "\n",
      "Real values: [1 0 1 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 0 0 1 1 1 0\n",
      " 1 1 0 1 1 0 1 1 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "def get_best_split(y, data):\n",
    "\n",
    "    masks = data.drop(y, axis= 1).apply(max_information_gain_split, y = data[y])\n",
    "    if sum(masks.loc[3,:]) == 0:\n",
    "        return(None, None, None, None)\n",
    "    else:\n",
    "        # Get only masks that can be splitted\n",
    "        masks = masks.loc[:,masks.loc[3,:]]\n",
    "\n",
    "        # Get the results for split with highest IG\n",
    "        split_variable = masks.iloc[0].astype(np.float32).idxmax()\n",
    "        \n",
    "    #split_valid = masks[split_variable][]\n",
    "    split_value = masks[split_variable][1]\n",
    "    split_ig = masks[split_variable][0]\n",
    "    split_numeric = masks[split_variable][2]\n",
    "\n",
    "    return(split_variable, split_value, split_ig, split_numeric)\n",
    "\n",
    "def make_split(variable, value, data, is_numeric):\n",
    "    if is_numeric:\n",
    "        data_1 = data[data[variable] < value]\n",
    "        data_2 = data[(data[variable] < value) == False]\n",
    "    \n",
    "    else:\n",
    "        data_1 = data[data[variable].isin(value)]\n",
    "        data_2 = data[(data[variable].isin(value)) == False]\n",
    "    \n",
    "    return(data_1,data_2)\n",
    "\n",
    "def make_prediction(data, target_factor):\n",
    "    # Make predictions\n",
    "    if target_factor:\n",
    "        pred = data.value_counts().idxmax()\n",
    "    else:\n",
    "        pred = data.mean()\n",
    "    return pred\n",
    "\n",
    "def train_tree(data,y, target_factor, max_depth = None,min_samples_split = None, min_information_gain = 1e-20, counter=0, max_categories = 20):\n",
    "    # Check that max_categories is fulfilled\n",
    "    if counter==0:\n",
    "        types = data.dtypes\n",
    "        check_columns = types[types == \"object\"].index\n",
    "        for column in check_columns:\n",
    "            var_length = len(data[column].value_counts())\n",
    "            if var_length > max_categories:\n",
    "                raise ValueError('The variable ' + column + ' has '+ str(var_length) + 'unique values, which is more than the accepted ones: ' + str(max_categories))\n",
    "    \n",
    "    # Check for depth conditions\n",
    "    if max_depth == None:\n",
    "        depth_cond = True\n",
    "    \n",
    "    else:\n",
    "        if counter < max_depth:\n",
    "            depth_cond = True\n",
    "        else:\n",
    "            depth_cond = False\n",
    "    \n",
    "    # Check for sample conditions\n",
    "    if min_samples_split == None:\n",
    "        sample_cond = True\n",
    "        \n",
    "    else:\n",
    "        if data.shape[0] > min_samples_split:\n",
    "            sample_cond = True\n",
    "        else:\n",
    "            sample_cond = False\n",
    "    \n",
    "    # Check for ig condition\n",
    "    if depth_cond & sample_cond:\n",
    "        var,val,ig,var_type = get_best_split(y, data)\n",
    "        \n",
    "        # If ig condition is fulfilled, make split\n",
    "        if ig is not None and ig >= min_information_gain:\n",
    "        \n",
    "            counter += 1\n",
    "        \n",
    "            left,right = make_split(var, val, data,var_type)\n",
    "            \n",
    "            # Instantiate sub-tree\n",
    "            split_type = \"<=\" if var_type else \"in\"\n",
    "            question = \"{} {} {}\".format(var,split_type,val)\n",
    "            \n",
    "            # question = \"\\n\" + counter*\" \" + \"|->\" + var + \" \" + split_type + \" \" +\n",
    "            str(val)\n",
    "            subtree = {question: []}\n",
    "        \n",
    "            # Find answers (recursion)\n",
    "            yes_answer = train_tree(left,y, target_factor, max_depth,min_samples_split,min_information_gain, counter)\n",
    "            no_answer = train_tree(right,y, target_factor, max_depth,min_samples_split,min_information_gain, counter)\n",
    "            if yes_answer == no_answer:\n",
    "                subtree = yes_answer\n",
    "            else:\n",
    "                subtree[question].append(yes_answer)\n",
    "                subtree[question].append(no_answer)\n",
    "        # If it doesn't match IG condition, make prediction\n",
    "        else:\n",
    "            pred = make_prediction(data[y],target_factor)\n",
    "            return pred\n",
    "    # Drop dataset if doesn't match depth or sample conditions\n",
    "    else:\n",
    "        pred = make_prediction(data[y],target_factor)\n",
    "        return pred\n",
    "    \n",
    "    return subtree\n",
    "\n",
    "max_depth = 5\n",
    "min_samples_split = 20\n",
    "min_information_gain = 1e-5\n",
    "\n",
    "decision = train_tree(data,'obese',True,\n",
    "max_depth,min_samples_split,min_information_gain)\n",
    "decision\n",
    "\n",
    "def classifier_data(observation, arbol):\n",
    "    question = list(arbol.keys())[0]\n",
    "    if question.split()[1] == '<=':\n",
    "        if observation[question.split()[0]] <= float(question.split()[2]):\n",
    "            answer = arbol[question][0]\n",
    "        else:\n",
    "            answer = arbol[question][1]\n",
    "    else:\n",
    "        if observation[question.split()[0]] in (question.split()[2]):\n",
    "            answer = arbol[question][0]\n",
    "        else:\n",
    "            answer = arbol[question][1]\n",
    "    \n",
    "    # If the answer is not a dictionary\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return classifier_data(observation, answer)\n",
    "\n",
    "#Prediction\n",
    "obese_prediction = []\n",
    "num_obs = 50\n",
    "\n",
    "for i in range(num_obs):\n",
    "    obs_pred = classifier_data(data.iloc[i,:], decision)\n",
    "    obese_prediction.append(obs_pred)\n",
    "\n",
    "print(\"Predictions: \",obese_prediction, \"\\n\\nReal values:\", data.obese[:num_obs].to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6017992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.96, 'Precision': 0.9375, 'Sensitivity_recall': 1.0, 'Specificity': 0.9, 'F1_score': 0.967741935483871}\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix\n",
    "from sklearn import metrics\n",
    "observation = data.obese[:num_obs].to_numpy()\n",
    "answer = obese_prediction\n",
    "confusion_matrix = metrics.confusion_matrix(observation, answer)\n",
    "\n",
    "# Menghitung Akurasi\n",
    "Accuracy = metrics.accuracy_score(observation, answer)\n",
    "\n",
    "# Menghitung Presisi\n",
    "Precision = metrics.precision_score(observation, answer)\n",
    "\n",
    "# Menghitung Sensitivitas\n",
    "Sensitivity_recall = metrics.recall_score(observation, answer)\n",
    "\n",
    "# Menghitung Spesifisitas\n",
    "Specificity = metrics.recall_score(observation, answer, pos_label=0)\n",
    "\n",
    "# Menghitung F-Score\n",
    "F1_score = metrics.f1_score(observation, answer)\n",
    "\n",
    "print({\"Accuracy\":Accuracy,\"Precision\":Precision,\"Sensitivity_recall\":Sensitivity_recall,\"Specificity\":Specificity,\"F1_score\":F1_score})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c747bb55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
